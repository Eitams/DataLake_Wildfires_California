{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This notebook helped to build the script, it is not formatted and not clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build lambda for RDS datalake for Weather data (historical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prompt data from RDS, Wildfires in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    conn = psycopg2.connect(\"host=firedb1.cscdg7rb1snc.us-east-1.rds.amazonaws.com dbname=FIREDB1 user=maren password=0123456789\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not get curser to the Database\")\n",
    "    print(e)\n",
    "    \n",
    "# Auto commit is very important\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>38.767220</td>\n",
       "      <td>-119.8167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>41.421398</td>\n",
       "      <td>-122.4981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>41.046330</td>\n",
       "      <td>-122.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>41.357780</td>\n",
       "      <td>-120.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>37.751220</td>\n",
       "      <td>-119.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>34.172500</td>\n",
       "      <td>-116.8266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>33.829170</td>\n",
       "      <td>-116.7631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>34.247230</td>\n",
       "      <td>-116.9277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>34.201170</td>\n",
       "      <td>-116.7913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>35.830970</td>\n",
       "      <td>-118.1619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        lat      long\n",
       "0     2016-05-05  38.767220 -119.8167\n",
       "1     2015-07-05  41.421398 -122.4981\n",
       "2     2019-08-10  41.046330 -122.0796\n",
       "3     2017-08-07  41.357780 -120.9694\n",
       "4     2017-08-06  37.751220 -119.1410\n",
       "...          ...        ...       ...\n",
       "1456  2021-08-10  34.172500 -116.8266\n",
       "1457  2021-08-30  33.829170 -116.7631\n",
       "1458  2021-08-30  34.247230 -116.9277\n",
       "1459  2021-08-30  34.201170 -116.7913\n",
       "1460  2021-09-10  35.830970 -118.1619\n",
       "\n",
       "[1461 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT FireDiscoveryDateTime, InitialLatitude, InitialLongitude FROM Firedata_Total;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "data=[]\n",
    "while row:\n",
    "    data.append(list(row))\n",
    "    row = cur.fetchone()\n",
    "data_fire=data\n",
    "header=['date','lat','long']\n",
    "df=pd.DataFrame(data, columns=header)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prompt historical data from Weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pprint\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually don't need the pandas DataFrame, we just need the data insinde, and nested list is much more easier!\n",
    "request_data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2016-05-05\n",
       "1      2015-07-05\n",
       "2      2019-08-10\n",
       "3      2017-08-07\n",
       "4      2017-08-06\n",
       "          ...    \n",
       "1456   2021-08-10\n",
       "1457   2021-08-30\n",
       "1458   2021-08-30\n",
       "1459   2021-08-30\n",
       "1460   2021-09-10\n",
       "Name: date, Length: 1461, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "j1=datetime.strptime('2021-06-10','%Y-%m-%d').date()\n",
    "j2=datetime.strptime('2021-10-10','%Y-%m-%d').date()\n",
    "print(type(j1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[df.date.between(j1,j2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 2 not imported\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print('row %i not imported'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "today=date.today()\n",
    "month_ago=today-timedelta(days=30)\n",
    "print(type(today))\n",
    "print(type(month_ago))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def API_query_history(loc, date, delta, apikey='Z3Z4Q9PHE3MSXWKUPQNQ8434D', unit='metric', agg='24'):\n",
    "    # This is the core of our weather query URL\n",
    "    BaseURL = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/weatherdata/history'\n",
    "\n",
    "    ApiKey=apikey\n",
    "    #UnitGroup sets the units of the output - us or metric\n",
    "    UnitGroup=unit\n",
    "\n",
    "    #Locations for the weather data. Multiple locations separated by pipe (|)\n",
    "    Locations=loc\n",
    "\n",
    "    #1=hourly, 24=daily\n",
    "    AggregateHours=agg\n",
    "\n",
    "    #Params for history only\n",
    "    date_of_interest=date\n",
    "    StartDate = str(date_of_interest+timedelta(days=-delta))\n",
    "    EndDate= str(date_of_interest+timedelta(days=delta))\n",
    "\n",
    "    # Set up the query\n",
    "    QueryParams = '?aggregateHours=' + AggregateHours + '&startDateTime=' + StartDate + '&endDateTime='+ EndDate + '&unitGroup=' + UnitGroup + '&shortColumnNames=true'\n",
    "\n",
    "    Locations='&locations=' + Locations\n",
    "\n",
    "    ApiKey='&key='+ApiKey\n",
    "\n",
    "    # Build the entire query\n",
    "    URL = BaseURL + QueryParams + Locations + ApiKey+\"&contentType=json\"\n",
    "\n",
    "    return URL\n",
    "\n",
    "#building header, only need to loop once\n",
    "def json_header_extractor():\n",
    "    dict_locations=weatherData['locations']\n",
    "    key_location=list(weatherData['locations'].keys())\n",
    "    header=[]\n",
    "    for key in dict_locations[str(key_location[0])].keys():\n",
    "        if key=='values':\n",
    "            header.extend(list(dict_locations[str(key_location[0])][key][0].keys()))\n",
    "        else:\n",
    "            header.append(key)\n",
    "    return header\n",
    "\n",
    "#building data, in the 'values' section, there is the data for the forecasted days, so if forecstDays=3, there is 3 elements in the list 'values'\n",
    "def json_data_extractor():\n",
    "    dict_locations=weatherData['locations']\n",
    "    key_location=list(weatherData['locations'].keys())\n",
    "    all_data=[]\n",
    "    for i in range((delta*2)+1):\n",
    "        data=[]\n",
    "        for key, value in dict_locations[str(key_location[0])].items():\n",
    "            if key=='values':\n",
    "                try:\n",
    "                    data.extend(list(dict_locations[str(key_location[0])][key][i].values()))\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                data.append(value)\n",
    "        all_data.append(data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "delta=2\n",
    "raw_data=[]\n",
    "for fire in request_data:\n",
    "    date=fire[0]\n",
    "    lat=fire[1]\n",
    "    long=fire[2]\n",
    "    loc=str(lat)+','+str(long)\n",
    "    URL=API_query_history(loc, date, delta)\n",
    "    print(URL)\n",
    "    response = urllib.request.urlopen(URL)\n",
    "    data = response.read()\n",
    "    weatherData = json.loads(data.decode('utf-8'))\n",
    "    if n==0:\n",
    "        header=json_header_extractor()\n",
    "        data=json_data_extractor()\n",
    "        raw_data.extend(data)\n",
    "        n+=1\n",
    "    else:\n",
    "        data=json_data_extractor()\n",
    "        raw_data.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build DataFrame\n",
    "df=pd.DataFrame(raw_data,columns=header)\n",
    "df_manip=df\n",
    "\n",
    "#Quick manipulation in order to facilitate the insertion  in the RDS tables (delete columns with no data, and re-arrange column order)\n",
    "# delete 'stationContribution', 'info', 'index', 'distance', 'time', 'currentConditions' , 'alerts' because they are empty columns -> no data\n",
    "df_manip=df_manip.drop(['stationContributions', 'datetime','info', 'index', 'distance', 'time', 'currentConditions' , 'alerts'], axis=1)\n",
    "\n",
    "# re-arrange column\n",
    "re_arrg_col=['tz','longitude','latitude','name','address','id']\n",
    "for col in re_arrg_col:\n",
    "    shiftpos=df_manip.pop(col)\n",
    "    df_manip.insert(0,col,shiftpos)\n",
    "\n",
    "#Save the DataFrame to .csv\n",
    "new_df=df_manip\n",
    "new_df.to_csv('weather_API_historical_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data in RDS datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ENDPOINT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\natr\\Desktop\\HSLU_S3\\DWL\\wild_fires_project\\DataLake_Wildfires_California\\historical_weather_lambda.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/natr/Desktop/HSLU_S3/DWL/wild_fires_project/DataLake_Wildfires_California/historical_weather_lambda.ipynb#ch0000015?line=0'>1</a>\u001b[0m ENDPOINT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mENDPOINT\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natr/Desktop/HSLU_S3/DWL/wild_fires_project/DataLake_Wildfires_California/historical_weather_lambda.ipynb#ch0000015?line=1'>2</a>\u001b[0m DB_NAME \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mDB_NAME\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natr/Desktop/HSLU_S3/DWL/wild_fires_project/DataLake_Wildfires_California/historical_weather_lambda.ipynb#ch0000015?line=2'>3</a>\u001b[0m USERNAME \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mUSERNAME\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/natr/AppData/Local/Programs/Python/Python39/lib/os.py?line=675'>676</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[0;32m    <a href='file:///c%3A/Users/natr/AppData/Local/Programs/Python/Python39/lib/os.py?line=676'>677</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/natr/AppData/Local/Programs/Python/Python39/lib/os.py?line=677'>678</a>\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/natr/AppData/Local/Programs/Python/Python39/lib/os.py?line=678'>679</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/natr/AppData/Local/Programs/Python/Python39/lib/os.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ENDPOINT'"
     ]
    }
   ],
   "source": [
    "ENDPOINT = os.environ['ENDPOINT']\n",
    "DB_NAME = os.environ['DB_NAME']\n",
    "USERNAME = os.environ['USERNAME']\n",
    "PASSWORD = os.environ['PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    #print(\"host={} dbname={} user={} password={}\".format(ENDPOINT, DB_NAME, USERNAME, PASSWORD))\n",
    "    #conn = psycopg2.connect(\"host={} dbname={} user={} password={}\".format(ENDPOINT, DB_NAME, USERNAME, PASSWORD))\n",
    "    conn = psycopg2.connect(\"host=datalake.cbqjcib7k7og.us-east-1.rds.amazonaws.com dbname=datalake_weather user=nathan password=123456789\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: ##\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not get curser to the Database\")\n",
    "    print(e)\n",
    "    \n",
    "# Auto commit is very important\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table for historical data\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS HISTORICAL_WEATHER_DATA (id VARCHAR(70), address VARCHAR(80), name VARCHAR(70), latitude FLOAT, longitude FLOAT, tz VARCHAR(30), wdir FLOAT, temp FLOAT, maxt FLOAT, visibility FLOAT, wspd FLOAT, datetimeStr DATE, solarenergy FLOAT, heatindex FLOAT, cloudcover FLOAT, mint FLOAT, precip FLOAT, solarradiation FLOAT, weathertype VARCHAR(120),\tsnowdepth FLOAT, sealevelpressure FLOAT, snow FLOAT, dew FLOAT, humidity FLOAT, precipcover FLOAT, wgust FLOAT, conditions VARCHAR(90), windchill FLOAT);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"TRUNCATE TABLE HISTORICAL_WEATHER_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "#Upload data in the table\n",
    "data=new_df\n",
    "\n",
    "cols = \",\".join([str(i) for i in data.columns.tolist()])\n",
    "\n",
    "imported_rows=0\n",
    "excluded_rows_index=[]\n",
    "for i,row in data.iterrows():\n",
    "    try:\n",
    "        sql = \"INSERT INTO HISTORICAL_WEATHER_DATA  (\" +cols + \") VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "        cur.execute(sql, tuple(row))\n",
    "        conn.commit()\n",
    "        imported_rows+=1\n",
    "    except:\n",
    "        excluded_rows_index.append(i)\n",
    "        print(i)\n",
    "print('Number of imported rows: ',imported_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"select count(*) from HISTORICAL_WEATHER_DATA;\")\n",
    "number_rows=cur.fetchall()[0][0]\n",
    "print(number_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6b7c4741759e6dff2d3609019adb5b2eb8766476d7e61b1a583782d03f4e08b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
